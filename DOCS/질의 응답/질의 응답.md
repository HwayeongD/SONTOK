## 데이터의 수가 너무 작은 것 같습니다. 추후 계획이 있나요??  
현재는 15 개의 단어에 대한 337 개의 데이터를 사용하여 학습을 진행하였습니다.  
이러한 개수를 설정한 이유는 6주라는 짧은 기간 동안 앱이 정상적으로 동작할 수 있는지에 대한 가능성을 보여드리기 위함입니다. 
추후 시간을 들여, 청각장애인 단체나 자원봉사자의 도움을 받는다면 더욱 넓은 범위에서 서비스 할 수 있을 것으로 기대됩니다.  

## 인식할 수 있는 수어가 몇 개가 있고 정확도는 어떤가요??  
현재 테스트용으로 배포되어 서비스 되고 있는 손톡에서 인식할 수 있는 수어의 개수는 15개 이고,  
실제 손톡 서비스를 사용해 보면서 정확도는 확인해 보았을 때, 67%의 정확도를 보입니다.  
추후 시간을 들여, 청각장애인 단체나 자원봉사자의 도움을 받는다면 더욱 넓은 범위에서 서비스 할 수 있을 것으로 기대됩니다.   

## 시끄러운 환경에서도 STT가 잘 인식 되나요??  
현재 손톡 서비스는 CLOVA의 STT를 사용하고 있습니다.  
시끄러운 환경에서는 잘 동작하지 않습니다.  
추후 목소리의 주파수 인식 기술등으로 개선될 수 있는 사항이라고 생각합니다.  

## STT와 TTS의 경우는 on-Device 형식이 아닌 것으로 보입니다. 인터넷이 연결되지 않은 상황에서는 사용할 수 없는 건가요??  
인터넷이 연결되지 않은 상황에서는 Clova api인 STT와 TTS가 동작하지 않습니다.  
궁극적인 목표로는 인터넷이 필요없는 환경에서도 동작하도록 하는 것이 목표입니다.  
따라서 on-Deive로 STT나 TTS 모델을 사용한다면 인터넷이 연결되지 않은, 오프라인 환경에서도 사용할 수 있을 것입니다.  

## z-flip에서만 사용할 수 있는 것인가요??
현재 z-flip 뿐만 아니라 바 형식의 일반적인 안드로이드 핸드폰에서도 "거치대가 있다면" z-flip에서와 같이 사용할 수 있도록 서비스 되고 있긴 합니다.  
두 손을 자유롭게 사용할 수 있는 환경이 수어를 사용하는 청각장애인에게 가장 중요한 점이라고 생각하였습니다.  
그렇기 때문에, 추가적인 장비 없이도 간편하게 "접어서 거치할 수 있는" z-flip을 타겟팅 하였습니다.  

## 수익성은 어떤가요??  
청각장애인이 삼성전자의 z-flip을 사용해야하는 이유를 만듦으로써 z-flip의 판매량 증가를 기대할 수 있다고 생각합니다.  

## 문맥이 부자연스러운데 해결할 수 있나요??  
삼성전자에서 개발 중인 생성형 AI 모델인 "삼성 가우스"나 open AI사의 "챗 GPT"를 사용하게 된다면 보다 자연스러운 대화가 가능할 것으로 기대됩니다.  

## 이 프로젝트의 주제를 선택한 계기가 있나요??  
대학교를 다니며, 청각장애를 가진 학우와 같은 수업을 들었던 적이 있습니다.  
수업지원 도우미 없이는 수업을 듣기 어려워하는 것이 기억에 남습니다.  
SSAFY 과정을 진행하며 이러한 학생들의 일상에 도움이 될 수는 없을까 라는 생각을 하게 되었고,  
청각장애인의 의사소통을 위한 주제를 선정하게 되었습니다.  

## 실제로 청각장애인에게 필드 테스트를 해본적이 있나요??  
아니요. 없습니다.  
현재 서비스 되고 있는 모델에서는 15개의 단어에 대한 서비스를 진행하고 있는데,  
추후, 실생활에 사용가능한 수준의 모델을 구현하게 된다면, 테스트를 진행해 보고 싶습니다.  